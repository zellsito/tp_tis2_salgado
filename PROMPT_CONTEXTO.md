# Prompt de Contexto - Proyecto TIS2 Aprendizaje Notebooks

## ğŸ¯ Objetivo del Proyecto

Aprender Jupyter Notebooks + Python + LangChain ejecutando y documentando notebooks paso a paso.

---

## ğŸ“‹ MetodologÃ­a de Trabajo

### Para cada notebook:
1. **Ejecutar celda por celda** (con Groq API gratuita)
2. **Documentar en archivo `.md`** con el mismo nombre (ej: `chatmodel.ipynb` â†’ `chatmodel.md`)
3. **Actualizar `notebooks/README.md`** agregando el nuevo notebook a la lista
4. **Mantener estructura organizada**

---

## ğŸ“‚ Estructura del Proyecto

```
tp_tis2_salgado/
â”œâ”€â”€ README.md                    # Proyecto principal (pendiente implementaciÃ³n)
â”œâ”€â”€ setup.md                     # Setup completo del entorno (Python, Groq, HuggingFace)
â”œâ”€â”€ .env                         # GROQ_API_KEY + OPENAI_MODEL=llama-3.1-8b-instant
â”œâ”€â”€ .gitignore                   # Archivos ignorados
â”œâ”€â”€ .venv/                       # Entorno virtual Python 3.11.2
â””â”€â”€ notebooks/
    â”œâ”€â”€ README.md                # Ãndice de todos los notebooks aprendidos
    â”œâ”€â”€ chatmodel.ipynb          # âœ… COMPLETADO
    â”œâ”€â”€ chatmodel.md             # âœ… DocumentaciÃ³n completa
    â”œâ”€â”€ semanticsearchnotebook.ipynb  # ğŸ“Œ SIGUIENTE
    â””â”€â”€ (otros notebooks...)
```

---

## âœ… Notebooks Completados

### 1. chatmodel.ipynb (COMPLETADO)
- **TamaÃ±o:** 13KB
- **Temas:** Prompting bÃ¡sico, chains, memoria, few-shot, structured output
- **Conceptos clave:**
  - Chaineo con pipe `|`
  - Templates con `{variables}`
  - Memoria (`InMemoryChatMessageHistory`)
  - Embeddings locales (`HuggingFaceEmbeddings`)
  - Zero-shot vs Few-shot
  - Structured output con Pydantic
- **Archivo de documentaciÃ³n:** `notebooks/chatmodel.md` (completo)

---

## ğŸ“Œ Siguiente Notebook Recomendado

### semanticsearchnotebook.ipynb
**Por quÃ© este?**
- âœ… TamaÃ±o pequeÃ±o (36KB) - fÃ¡cil de completar
- âœ… Relacionado con `chatmodel.ipynb` (usa embeddings)
- âœ… Introduce bÃºsqueda semÃ¡ntica (concepto clave para RAG)
- âœ… Usa ChromaDB (ya instalado)
- âœ… Complejidad baja-media

**Temas que cubre:**
- Embeddings y vectorizaciÃ³n
- BÃºsqueda semÃ¡ntica
- Base de datos vectorial (Chroma)
- Similarity search

**Siguiente despuÃ©s:** `raglangchain.ipynb` (RAG bÃ¡sico)

---

## ğŸ“Š Inventario Completo de Notebooks (11 total)

### ğŸ¯ Notebooks de LLM/LangChain (Prioridad Alta - 8 notebooks)

| # | Notebook | TamaÃ±o | Estado | Complejidad | Temas |
|---|----------|--------|--------|-------------|-------|
| 1 | chatmodel.ipynb | 13KB | âœ… COMPLETADO | Baja | Prompting, chains, memoria |
| 2 | semanticsearchnotebook.ipynb | 32KB | âœ… COMPLETADO | Baja-Media | Embeddings, bÃºsqueda semÃ¡ntica |
| 3 | raglangchain.ipynb | 33KB | âœ… COMPLETADO | Media | RAG + re-ranking |
| 4 | react-web-search.ipynb | 49KB | âœ… COMPLETADO | Media | ReAct agents + Tavily |
| 5 | agentic-rag.ipynb | 393KB | âœ… COMPLETADO | Alta | RAG con flujo decisiones |
| 6 | raglangchaimongodb.ipynb | 263KB | ğŸ“Œ SIGUIENTE | Media-Alta | RAG + MongoDB |
| 7 | sql-agent.ipynb | 1.1MB | â³ PENDIENTE | Alta | Agentes + SQL + LangGraph |
| 8 | langchainmultiagentcollaboration.ipynb | 1.1MB | â³ PENDIENTE | Muy Alta | Multi-agentes colaborativos |

### ğŸ“Š Notebooks de ML/Data Science (Prioridad Baja - 3 notebooks)

| # | Notebook | TamaÃ±o | Estado | Tema |
|---|----------|--------|--------|------|
| 9 | pneumoniapreprocessing.ipynb | 47KB | â¸ï¸ OPCIONAL | Preprocesamiento imÃ¡genes |
| 10 | salarypredictionregression.ipynb | 144KB | â¸ï¸ OPCIONAL | RegresiÃ³n ML |
| 11 | customerchurnclassification-fs.ipynb | 529KB | â¸ï¸ OPCIONAL | ClasificaciÃ³n ML |

**Progreso LLM/LangChain:** 5/8 completados (62.5%)
**Progreso Total:** 5/11 notebooks (45.5%)

---

## ğŸ› ï¸ ConfiguraciÃ³n Actual

### Entorno
- Python 3.11.2
- Entorno virtual `.venv` activo
- VS Code con extensiÃ³n Jupyter

### Dependencias Instaladas
```bash
# LLM & LangChain
langchain
langchain-core
langchain-community
langchain-groq
langchain-openai
langchain-chroma

# Embeddings locales
sentence-transformers
langchain-huggingface

# Utilidades
python-dotenv
jupyter

# Total: ~3GB
```

### API Keys (.env)
```bash
GROQ_API_KEY=***REMOVED***
OPENAI_MODEL=llama-3.1-8b-instant
```

---

## ğŸ“ Formato de DocumentaciÃ³n (template)

Para cada notebook crear archivo `<nombre>.md` con:

```markdown
# Aprendizaje: <nombre>.ipynb

## ğŸ“‹ Ãndice de Celdas
(Tabla con todas las celdas numeradas)

## ğŸ”§ Errores Encontrados y Corregidos
(Si aplica)

## ğŸ“š Conceptos Clave
(ExplicaciÃ³n de conceptos principales)

## ğŸ“ ExplicaciÃ³n por Celda
(Solo celdas ejecutables)

## ğŸ¯ Resumen Ejecutivo
(Tabla de conceptos)

## âœ… Checklist de EjecuciÃ³n

## ğŸ“ Aprendizajes Clave

## ğŸ“ Notas Finales
```

---

## ğŸ”„ Flujo de Trabajo

### Al empezar un nuevo notebook:

1. **Abrir notebook** en VS Code
2. **Seleccionar kernel** `.venv/bin/python`
3. **Ejecutar celdas** de arriba hacia abajo
4. **Anotar errores** y soluciones
5. **Crear archivo `.md`** con documentaciÃ³n completa
6. **Actualizar `notebooks/README.md`** agregando entrada del nuevo notebook
7. **Verificar** que todo funcione
8. **(Opcional) Limpiar contexto** de Claude Code para ahorrar tokens

---

## ğŸ“– Archivos de Referencia

- **`setup.md`** - Setup completo (consultar si hay errores de instalaciÃ³n)
- **`notebooks/chatmodel.md`** - Ejemplo de documentaciÃ³n completa
- **`notebooks/README.md`** - Ãndice de notebooks aprendidos

---

## ğŸš¨ Correcciones Aplicadas (para referencia futura)

### chatmodel.ipynb
1. **Import deprecado:**
   - âŒ `from langchain.memory import ChatMessageHistory`
   - âœ… `from langchain_core.chat_history import InMemoryChatMessageHistory`

2. **Modelo Groq deprecado:**
   - âŒ `llama-3.1-70b-versatile`
   - âœ… `llama-3.1-8b-instant`

3. **Embeddings (OpenAI â†’ HuggingFace):**
   - âŒ `from langchain_openai import OpenAIEmbeddings`
   - âœ… `from langchain_huggingface import HuggingFaceEmbeddings`
   - âŒ `OpenAIEmbeddings()`
   - âœ… `HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")`

### raglangchain.ipynb (ADAPTADO âœ…)
1. **Celda 0359a684 (imports - TODOS actualizados para LangChain 1.0+):**
   - âŒ `from langchain.document_loaders import PyPDFLoader`
   - âœ… `from langchain_community.document_loaders import PyPDFLoader`
   - âŒ `from langchain.text_splitter import RecursiveCharacterTextSplitter`
   - âœ… `from langchain_text_splitters import RecursiveCharacterTextSplitter`
   - âŒ `from langchain.schema import Document`
   - âœ… `from langchain_core.documents import Document`
   - âŒ `from langchain.vectorstores.chroma import Chroma`
   - âœ… `from langchain_chroma import Chroma`
   - âŒ `from langchain.schema.runnable import RunnablePassthrough`
   - âœ… `from langchain_core.runnables import RunnablePassthrough`
   - âŒ `from langchain.schema.output_parser import StrOutputParser`
   - âœ… `from langchain_core.output_parsers import StrOutputParser`
   - âŒ `from langchain import hub`
   - âœ… `from langsmith import Client as LangSmithClient` + `hub_client = LangSmithClient()`
   - âŒ `from langchain_openai import OpenAIEmbeddings, ChatOpenAI`
   - âœ… `from langchain_huggingface import HuggingFaceEmbeddings`
   - âœ… `from langchain_groq import ChatGroq`
2. **Celda 8o9x9mda5pj (nueva, configuraciÃ³n embeddings):**
   - âœ… `EMBEDDING_MODEL = "all-MiniLM-L6-v2"`
   - âœ… `embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)`
3. **Celda 90cab636 (dataset path):**
   - âŒ `input_datapath = "../semantic-search/dataset.json"`
   - âœ… `input_datapath = "dataset.json"`
4. **Celda 69dd1aea (InMemoryVectorStore):**
   - âŒ `InMemoryVectorStore(OpenAIEmbeddings())`
   - âœ… `InMemoryVectorStore(embeddings)`
5. **Celda 964b9696 (LLM):**
   - âŒ `ChatOpenAI(model=llm_model, temperature=0.1)`
   - âœ… `ChatGroq(model=llm_model, temperature=0.1)`
6. **Celda 9f41466a (hub.pull):**
   - âŒ `rag_prompt = hub.pull("rlm/rag-prompt")`
   - âœ… `rag_prompt = hub_client.pull_prompt("rlm/rag-prompt")`
7. **Celda 1779f900 (Chroma):**
   - âŒ `Chroma.from_documents(cleaned_texts, OpenAIEmbeddings())`
   - âœ… `Chroma.from_documents(cleaned_texts, embeddings)`
8. **Celdas 3652ba2b, 7250b7ca, 1316d1f7 (Re-ranking - COMPLETADO âœ…):**
   - âœ… Implementado re-ranking manual con `CrossEncoder`
   - âœ… FunciÃ³n `rerank_documents()` creada
   - âœ… Clase `RerankedRetriever` para integrar re-ranking en chains
   - âœ… RAG chain con re-ranking funcionando correctamente
9. **Datos preparados:**
   - âœ… PDF copiado a `notebooks/data/Understanding_Climate_Change.pdf`
   - âœ… Dataset de pelÃ­culas en mismo directorio

### raglangchain.ipynb - Errores Corregidos (COMPLETO âœ…)

**Error 1: MÃºltiples imports deprecados (LangChain 1.0+)**
```python
# âŒ Errores: No module named 'langchain.schema', 'langchain.retrievers', etc.

# Causa: LangChain 1.0+ reorganizÃ³ todos los mÃ³dulos en paquetes separados

# âœ… SoluciÃ³n: Usar imports especÃ­ficos de cada paquete
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_chroma import Chroma
```

**Error 2: hub.pull() no disponible**
```python
# âŒ Error: cannot import name 'hub' from 'langchain'
# âŒ langchainhub estÃ¡ deprecado

# âœ… SoluciÃ³n: Usar langsmith Client (langsmith ya instalado)
from langsmith import Client as LangSmithClient
hub_client = LangSmithClient()
rag_prompt = hub_client.pull_prompt("rlm/rag-prompt")
```

**Error 3: ContextualCompressionRetriever no disponible (SOLUCIONADO âœ…)**
```python
# âŒ Error: No module named 'langchain.retrievers'
# âŒ ContextualCompressionRetriever removido en LangChain 1.0+

# âœ… SoluciÃ³n: Implementar re-ranking manual con CrossEncoder
from sentence_transformers import CrossEncoder

cross_encoder_model = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-6-v2")

def rerank_documents(query: str, documents: list, top_n: int = 3):
    """Re-rankea documentos usando cross-encoder"""
    pairs = [[query, doc.page_content] for doc in documents]
    scores = cross_encoder_model.predict(pairs)
    scored_docs = list(zip(documents, scores))
    scored_docs.sort(key=lambda x: x[1], reverse=True)
    return [doc for doc, score in scored_docs[:top_n]]

# Retriever personalizado con re-ranking integrado
class RerankedRetriever:
    def __init__(self, base_retriever, rerank_function, top_n=3):
        self.base_retriever = base_retriever
        self.rerank_function = rerank_function
        self.top_n = top_n

    def invoke(self, query: str):
        docs = self.base_retriever.invoke(query)
        return self.rerank_function(query, docs, self.top_n)
```

**Error 4: OpenAI API key no configurada**
```python
# âœ… SoluciÃ³n: Usar alternativas gratuitas
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_groq import ChatGroq
```

**Error 5: Path incorrecto del dataset**
```python
# âŒ input_datapath = "../semantic-search/dataset.json"
# âœ… input_datapath = "dataset.json"
```

**Error 6: RAGxplorer no instalado y con imports deprecados**
```python
# âŒ Error: No module named 'ragexplorer'
# Causa: No estÃ¡ disponible en PyPI normalmente

# âœ… SoluciÃ³n: Instalar desde GitHub
pip install git+https://github.com/gabrielchua/RAGxplorer.git

# âœ… Parche imports deprecados en ragxplorer/rag.py:
from langchain_text_splitters import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter

# âœ… Parche bug en ragxplorer/projections.py (lÃ­nea 47):
if isinstance(embedding, list):
    embedding = np.array(embedding)
```

**Error 7: HyDE retrieval method con bug en RAGxplorer**
```python
# âŒ retrieval_method="HyDE" causa AttributeError con embeddings locales
# âœ… Usar retrieval_method="naive" (mÃ©todo bÃ¡sico funciona correctamente)
```

**Celda 64463bd5 (instalaciÃ³n):**
- âœ… `ragexplorer` instalado desde GitHub
- âœ… `nbformat` ya instalado

**Celda 367b91c6 (inicializaciÃ³n):**
- âŒ `RAGxplorer(embedding_model="text-embedding-3-small")` (OpenAI)
- âœ… `RAGxplorer(embedding_model="all-MiniLM-L6-v2")` (local, gratis)

**Celda 4d895962 (visualizaciÃ³n):**
- âŒ `retrieval_method="HyDE"` (bug con embeddings locales)
- âœ… `retrieval_method="naive"` (mÃ©todo bÃ¡sico, funciona bien)

---

### semanticsearchnotebook.ipynb (ADAPTADO âœ…)
1. **Celda 482c51f4:** Comentada instalaciÃ³n de OpenAI, todo ya instalado en .venv
2. **Celda 3a43fb47 (imports):**
   - âŒ `import openai`
   - âŒ `from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction`
   - âœ… `from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction`
3. **Celda a3fbd451 (setup):**
   - âŒ Todo bloque OpenAI API key comentado
   - âœ… `EMBEDDING_MODEL = "all-MiniLM-L6-v2"` (modelo local)
4. **Celda cd722937 (ChromaDB):**
   - âŒ `OpenAIEmbeddingFunction(api_key=..., model_name=...)`
   - âœ… `SentenceTransformerEmbeddingFunction(model_name=EMBEDDING_MODEL)`
5. **Dataset limpiado:**
   - âŒ `dataset.json` tenÃ­a embeddings OpenAI pre-calculados (dimensiÃ³n 1536)
   - âœ… Backup creado: `dataset_original_with_openai_embeddings.json` (210KB)
   - âœ… `dataset.json` nuevo (8.6KB) sin embeddings, ChromaDB los genera localmente
6. **Celda d3743ae9 (Create Collection):**
   - âŒ `embeddings=df.embedding.tolist()` (usaba embeddings pre-calculados)
   - âœ… `documents=documents` (ChromaDB genera embeddings automÃ¡ticamente)
7. **Celda 50ce16b3 (Preview):**
   - âŒ Esperaba embeddings en dataset
   - âœ… Indica que ChromaDB generarÃ¡ embeddings localmente

---

## ğŸ’¡ Tips de Trabajo

### Jupyter Notebooks
- El kernel se reinicia al cerrar â†’ re-ejecutar celdas al abrir
- Siempre ejecutar de arriba hacia abajo
- Usar "Run All" para ejecutar todo de una vez

### Claude Code
- Cuando el contexto sea muy largo (>100k tokens), limpiarlo:
  1. Guardar este archivo `PROMPT_CONTEXTO.md`
  2. Copiar contenido
  3. Reiniciar sesiÃ³n de Claude Code
  4. Pegar el prompt para retomar

### DocumentaciÃ³n
- Ser conciso pero completo
- Incluir ejemplos de cÃ³digo
- Explicar el "por quÃ©", no solo el "quÃ©"
- Agregar comparaciones con otros lenguajes si ayuda (ej: TypeScript)

---

## ğŸ¯ PrÃ³ximo Paso Inmediato

**Ejecutar y documentar: `semanticsearchnotebook.ipynb`**

1. Abrir `notebooks/semanticsearchnotebook.ipynb`
2. Seleccionar kernel `.venv/bin/python`
3. Ejecutar celdas en orden
4. Crear `notebooks/semanticsearchnotebook.md`
5. Actualizar `notebooks/README.md`

---

## ğŸ“ Forma de Trabajo con Claude Code

**Instrucciones claras:**
- "Ejecuta la celda X y documenta quÃ© hace"
- "Hay un error en la celda Y, corrigelo y documenta la soluciÃ³n"
- "Actualiza notebooks/README.md agregando semanticsearchnotebook"
- "MuÃ©strame un resumen de lo aprendido en esta sesiÃ³n"

**Lo que Claude Code debe hacer:**
- Leer notebooks
- Ejecutar cÃ³digo (cuando sea posible)
- Documentar explicaciones
- Corregir errores
- Mantener archivos actualizados
- Ser conciso pero completo

---

## âœ… Estado Actual

- âœ… Setup completo
- âœ… `chatmodel.ipynb` completado y documentado
- âœ… `semanticsearchnotebook.ipynb` completado y documentado
- âœ… `raglangchain.ipynb` completado y documentado
  - âœ… Dependencias instaladas (pypdf, langsmith, ragexplorer)
  - âœ… Notebook adaptado (OpenAI â†’ Groq + HuggingFace)
  - âœ… PDF preparado en notebooks/data/
  - âœ… RAGxplorer configurado con embeddings locales
  - âœ… Todos los imports actualizados para LangChain 1.0+
  - âœ… Re-ranking implementado con CrossEncoder (ms-marco-MiniLM-L-6-v2)
  - âœ… VisualizaciÃ³n RAGxplorer funcionando
- âœ… `react-web-search.ipynb` adaptado y documentado
  - âœ… Tavily API key configurada
  - âœ… Dependencias instaladas (langgraph, langchain-tavily)
  - âœ… LLM adaptado (OpenAI â†’ Groq)
  - âœ… Tests exitosos
- âœ… `agentic-rag.ipynb` completado y documentado
  - âœ… Todos los imports actualizados a LangChain 1.0+
  - âœ… LLM adaptado (OpenAI â†’ Groq)
  - âœ… Embeddings adaptados (OpenAI â†’ HuggingFace local)
  - âœ… LangGraph workflow con nodos de decisiÃ³n inteligentes
  - âœ… PDF de ejemplo disponible (Understanding_Climate_Change.pdf)
  - âœ… Flujo completo: query generation â†’ retrieval â†’ grading â†’ rewriting â†’ answer
- ğŸ¯ **Objetivo:** Aprender 8 notebooks de LLM/LangChain (+ 3 opcionales de ML)
- ğŸ“ **Progreso LLM:** 5/8 completado (62.5%)
- ğŸ“ **Progreso Total:** 5/11 notebooks (45.5%)

---

## ğŸ¯ PrÃ³ximos Pasos Recomendados

### OpciÃ³n A: raglangchaimongodb.ipynb â­ RECOMENDADA
**Por quÃ© seguir con este:**
- âœ… Continuidad lÃ³gica despuÃ©s de RAG bÃ¡sico + agentic-rag
- âœ… Introduce persistencia con MongoDB (crucial para apps reales)
- âœ… TamaÃ±o mediano (263KB) - abordable despuÃ©s de agentic-rag (393KB)
- âœ… Complejidad Media-Alta (desafiante pero no abrumador)
- âœ… Combina RAG + Base de datos vectorial + Filtros tradicionales

**Temas que aprenderÃ¡s:**
- MongoDB Atlas como vector store
- Persistencia de embeddings en BD NoSQL
- Queries hÃ­bridas (vectorial + metadatos)
- IntegraciÃ³n LangChain + PyMongo

### OpciÃ³n B: sql-agent.ipynb
**Consideraciones:**
- âš ï¸ 1.1MB (muy extenso, >3x mÃ¡s grande que mongodb)
- âš ï¸ Complejidad Alta
- âœ… Prerequisitos cumplidos (react-web-search + agentic-rag)
- RecomendaciÃ³n: Dejar para despuÃ©s de mongodb

### OpciÃ³n C: Notebooks ML/Data Science
- Solo si querÃ©s cambiar de tema temporalmente
- Menor prioridad para LangChain/LLM

---

**Ãšltima actualizaciÃ³n:** 2025-11-07
**SesiÃ³n actual:** agentic-rag.ipynb COMPLETADO âœ…
**Siguiente recomendado:** raglangchaimongodb.ipynb (RAG + MongoDB, 263KB)
**Notebooks pendientes LLM:** 3 (mongodb, sql-agent, multiagent)
