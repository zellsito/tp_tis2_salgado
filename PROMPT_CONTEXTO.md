# Prompt de Contexto - Proyecto TIS2 Aprendizaje Notebooks

## ğŸ¯ Objetivo del Proyecto

Aprender Jupyter Notebooks + Python + LangChain ejecutando y documentando notebooks paso a paso.

---

## ğŸ“‹ MetodologÃ­a de Trabajo

### Para cada notebook:
1. **Ejecutar celda por celda** (con Groq API gratuita)
2. **Documentar en archivo `.md`** con el mismo nombre (ej: `chatmodel.ipynb` â†’ `chatmodel.md`)
3. **Actualizar `notebooks/README.md`** agregando el nuevo notebook a la lista
4. **Mantener estructura organizada**

---

## ğŸ“‚ Estructura del Proyecto

```
tp_tis2_salgado/
â”œâ”€â”€ README.md                    # Proyecto principal (pendiente implementaciÃ³n)
â”œâ”€â”€ setup.md                     # Setup completo del entorno (Python, Groq, HuggingFace)
â”œâ”€â”€ .env                         # GROQ_API_KEY + OPENAI_MODEL=llama-3.1-8b-instant
â”œâ”€â”€ .gitignore                   # Archivos ignorados
â”œâ”€â”€ .venv/                       # Entorno virtual Python 3.11.2
â””â”€â”€ notebooks/
    â”œâ”€â”€ README.md                # Ãndice de todos los notebooks aprendidos
    â”œâ”€â”€ chatmodel.ipynb          # âœ… COMPLETADO
    â”œâ”€â”€ chatmodel.md             # âœ… DocumentaciÃ³n completa
    â”œâ”€â”€ semanticsearchnotebook.ipynb  # ğŸ“Œ SIGUIENTE
    â””â”€â”€ (otros notebooks...)
```

---

## âœ… Notebooks Completados

### 1. chatmodel.ipynb (COMPLETADO)
- **TamaÃ±o:** 13KB
- **Temas:** Prompting bÃ¡sico, chains, memoria, few-shot, structured output
- **Conceptos clave:**
  - Chaineo con pipe `|`
  - Templates con `{variables}`
  - Memoria (`InMemoryChatMessageHistory`)
  - Embeddings locales (`HuggingFaceEmbeddings`)
  - Zero-shot vs Few-shot
  - Structured output con Pydantic
- **Archivo de documentaciÃ³n:** `notebooks/chatmodel.md` (completo)

---

## ğŸ“Œ Siguiente Notebook Recomendado

### semanticsearchnotebook.ipynb
**Por quÃ© este?**
- âœ… TamaÃ±o pequeÃ±o (36KB) - fÃ¡cil de completar
- âœ… Relacionado con `chatmodel.ipynb` (usa embeddings)
- âœ… Introduce bÃºsqueda semÃ¡ntica (concepto clave para RAG)
- âœ… Usa ChromaDB (ya instalado)
- âœ… Complejidad baja-media

**Temas que cubre:**
- Embeddings y vectorizaciÃ³n
- BÃºsqueda semÃ¡ntica
- Base de datos vectorial (Chroma)
- Similarity search

**Siguiente despuÃ©s:** `raglangchain.ipynb` (RAG bÃ¡sico)

---

## ğŸ”„ Orden de Aprendizaje Recomendado (por complejidad)

| Orden | Notebook | TamaÃ±o | Complejidad | Temas |
|-------|----------|--------|-------------|-------|
| 1 | âœ… `chatmodel.ipynb` | 13KB | Baja | Prompting, chains, memoria |
| 2 | ğŸ“Œ `semanticsearchnotebook.ipynb` | 36KB | Baja-Media | Embeddings, bÃºsqueda semÃ¡ntica |
| 3 | `react-web-search.ipynb` | 78KB | Media | ReAct agents, web search |
| 4 | `raglangchain.ipynb` | 254KB | Media | RAG bÃ¡sico |
| 5 | `raglangchaimongodb.ipynb` | 258KB | Media-Alta | RAG + MongoDB |
| 6 | `agentic-rag.ipynb` | 385KB | Alta | RAG con agentes |
| 7 | `sql-agent.ipynb` | 1.1MB | Alta | Agentes SQL |
| 8 | `langchainmultiagentcollaboration.ipynb` | 1.1MB | Muy Alta | Multi-agentes |

**Notebooks de ML/Data Science (opcionales, menor prioridad):**
- `salarypredictionregression.ipynb` (141KB)
- `customerchurnclassification-fs.ipynb` (517KB)
- `pneumoniapreprocessing.ipynb` (46KB)

---

## ğŸ› ï¸ ConfiguraciÃ³n Actual

### Entorno
- Python 3.11.2
- Entorno virtual `.venv` activo
- VS Code con extensiÃ³n Jupyter

### Dependencias Instaladas
```bash
# LLM & LangChain
langchain
langchain-core
langchain-community
langchain-groq
langchain-openai
langchain-chroma

# Embeddings locales
sentence-transformers
langchain-huggingface

# Utilidades
python-dotenv
jupyter

# Total: ~3GB
```

### API Keys (.env)
```bash
GROQ_API_KEY=***REMOVED***
OPENAI_MODEL=llama-3.1-8b-instant
```

---

## ğŸ“ Formato de DocumentaciÃ³n (template)

Para cada notebook crear archivo `<nombre>.md` con:

```markdown
# Aprendizaje: <nombre>.ipynb

## ğŸ“‹ Ãndice de Celdas
(Tabla con todas las celdas numeradas)

## ğŸ”§ Errores Encontrados y Corregidos
(Si aplica)

## ğŸ“š Conceptos Clave
(ExplicaciÃ³n de conceptos principales)

## ğŸ“ ExplicaciÃ³n por Celda
(Solo celdas ejecutables)

## ğŸ¯ Resumen Ejecutivo
(Tabla de conceptos)

## âœ… Checklist de EjecuciÃ³n

## ğŸ“ Aprendizajes Clave

## ğŸ“ Notas Finales
```

---

## ğŸ”„ Flujo de Trabajo

### Al empezar un nuevo notebook:

1. **Abrir notebook** en VS Code
2. **Seleccionar kernel** `.venv/bin/python`
3. **Ejecutar celdas** de arriba hacia abajo
4. **Anotar errores** y soluciones
5. **Crear archivo `.md`** con documentaciÃ³n completa
6. **Actualizar `notebooks/README.md`** agregando entrada del nuevo notebook
7. **Verificar** que todo funcione
8. **(Opcional) Limpiar contexto** de Claude Code para ahorrar tokens

---

## ğŸ“– Archivos de Referencia

- **`setup.md`** - Setup completo (consultar si hay errores de instalaciÃ³n)
- **`notebooks/chatmodel.md`** - Ejemplo de documentaciÃ³n completa
- **`notebooks/README.md`** - Ãndice de notebooks aprendidos

---

## ğŸš¨ Correcciones Aplicadas (para referencia futura)

### chatmodel.ipynb
1. **Import deprecado:**
   - âŒ `from langchain.memory import ChatMessageHistory`
   - âœ… `from langchain_core.chat_history import InMemoryChatMessageHistory`

2. **Modelo Groq deprecado:**
   - âŒ `llama-3.1-70b-versatile`
   - âœ… `llama-3.1-8b-instant`

3. **Embeddings (OpenAI â†’ HuggingFace):**
   - âŒ `from langchain_openai import OpenAIEmbeddings`
   - âœ… `from langchain_huggingface import HuggingFaceEmbeddings`
   - âŒ `OpenAIEmbeddings()`
   - âœ… `HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")`

### raglangchain.ipynb (ADAPTADO âœ…)
1. **Celda 0359a684 (imports):**
   - âŒ `from langchain_openai import OpenAIEmbeddings`
   - âŒ `from langchain_openai import ChatOpenAI`
   - âœ… `from langchain_huggingface import HuggingFaceEmbeddings`
   - âœ… `from langchain_groq import ChatGroq`
2. **Celda 8o9x9mda5pj (nueva, configuraciÃ³n embeddings):**
   - âœ… `EMBEDDING_MODEL = "all-MiniLM-L6-v2"`
   - âœ… `embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)`
3. **Celda 69dd1aea (InMemoryVectorStore):**
   - âŒ `InMemoryVectorStore(OpenAIEmbeddings())`
   - âœ… `InMemoryVectorStore(embeddings)`
4. **Celda 964b9696 (LLM):**
   - âŒ `ChatOpenAI(model=llm_model, temperature=0.1)`
   - âœ… `ChatGroq(model=llm_model, temperature=0.1)`
5. **Celda 1779f900 (Chroma):**
   - âŒ `Chroma.from_documents(cleaned_texts, OpenAIEmbeddings())`
   - âœ… `Chroma.from_documents(cleaned_texts, embeddings)`
6. **Datos preparados:**
   - âœ… PDF copiado a `notebooks/data/Understanding_Climate_Change.pdf`
   - âœ… Dataset de pelÃ­culas en `../semantic-search/dataset.json` (ya existe)

### semanticsearchnotebook.ipynb (ADAPTADO âœ…)
1. **Celda 482c51f4:** Comentada instalaciÃ³n de OpenAI, todo ya instalado en .venv
2. **Celda 3a43fb47 (imports):**
   - âŒ `import openai`
   - âŒ `from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction`
   - âœ… `from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction`
3. **Celda a3fbd451 (setup):**
   - âŒ Todo bloque OpenAI API key comentado
   - âœ… `EMBEDDING_MODEL = "all-MiniLM-L6-v2"` (modelo local)
4. **Celda cd722937 (ChromaDB):**
   - âŒ `OpenAIEmbeddingFunction(api_key=..., model_name=...)`
   - âœ… `SentenceTransformerEmbeddingFunction(model_name=EMBEDDING_MODEL)`
5. **Dataset limpiado:**
   - âŒ `dataset.json` tenÃ­a embeddings OpenAI pre-calculados (dimensiÃ³n 1536)
   - âœ… Backup creado: `dataset_original_with_openai_embeddings.json` (210KB)
   - âœ… `dataset.json` nuevo (8.6KB) sin embeddings, ChromaDB los genera localmente
6. **Celda d3743ae9 (Create Collection):**
   - âŒ `embeddings=df.embedding.tolist()` (usaba embeddings pre-calculados)
   - âœ… `documents=documents` (ChromaDB genera embeddings automÃ¡ticamente)
7. **Celda 50ce16b3 (Preview):**
   - âŒ Esperaba embeddings en dataset
   - âœ… Indica que ChromaDB generarÃ¡ embeddings localmente

---

## ğŸ’¡ Tips de Trabajo

### Jupyter Notebooks
- El kernel se reinicia al cerrar â†’ re-ejecutar celdas al abrir
- Siempre ejecutar de arriba hacia abajo
- Usar "Run All" para ejecutar todo de una vez

### Claude Code
- Cuando el contexto sea muy largo (>100k tokens), limpiarlo:
  1. Guardar este archivo `PROMPT_CONTEXTO.md`
  2. Copiar contenido
  3. Reiniciar sesiÃ³n de Claude Code
  4. Pegar el prompt para retomar

### DocumentaciÃ³n
- Ser conciso pero completo
- Incluir ejemplos de cÃ³digo
- Explicar el "por quÃ©", no solo el "quÃ©"
- Agregar comparaciones con otros lenguajes si ayuda (ej: TypeScript)

---

## ğŸ¯ PrÃ³ximo Paso Inmediato

**Ejecutar y documentar: `semanticsearchnotebook.ipynb`**

1. Abrir `notebooks/semanticsearchnotebook.ipynb`
2. Seleccionar kernel `.venv/bin/python`
3. Ejecutar celdas en orden
4. Crear `notebooks/semanticsearchnotebook.md`
5. Actualizar `notebooks/README.md`

---

## ğŸ“ Forma de Trabajo con Claude Code

**Instrucciones claras:**
- "Ejecuta la celda X y documenta quÃ© hace"
- "Hay un error en la celda Y, corrigelo y documenta la soluciÃ³n"
- "Actualiza notebooks/README.md agregando semanticsearchnotebook"
- "MuÃ©strame un resumen de lo aprendido en esta sesiÃ³n"

**Lo que Claude Code debe hacer:**
- Leer notebooks
- Ejecutar cÃ³digo (cuando sea posible)
- Documentar explicaciones
- Corregir errores
- Mantener archivos actualizados
- Ser conciso pero completo

---

## âœ… Estado Actual

- âœ… Setup completo
- âœ… `chatmodel.ipynb` completado y documentado
- âœ… `semanticsearchnotebook.ipynb` completado y documentado
- ğŸ”„ **En progreso:** raglangchain.ipynb (RAG = bÃºsqueda semÃ¡ntica + LLM)
  - âœ… Dependencias instaladas (pypdf, langsmith)
  - âœ… Notebook adaptado (OpenAI â†’ Groq + HuggingFace)
  - âœ… PDF preparado en notebooks/data/
  - â³ Listo para ejecutar
- ğŸ¯ **Objetivo:** Aprender 8 notebooks principales
- ğŸ“ **Progreso:** 2/8 completado (25%), 3er notebook en progreso

---

**Ãšltima actualizaciÃ³n:** 2025-11-06
**SesiÃ³n actual:** raglangchain.ipynb adaptado, listo para ejecutar
**PrÃ³xima sesiÃ³n:** Ejecutar raglangchain.ipynb celda por celda
**Nota:** RAG combina bÃºsqueda semÃ¡ntica + LLM para responder con contexto
