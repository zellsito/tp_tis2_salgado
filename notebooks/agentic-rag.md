# Aprendizaje: agentic-rag.ipynb

## üìã Resumen

**Notebook:** agentic-rag.ipynb (385KB adaptado)
**Tema:** Agentic RAG - RAG con flujo de decisiones inteligentes
**Estado:** ‚úÖ Adaptado y funcional
**Fecha:** 2025-11-07

### üéØ Objetivo
Aprender **Agentic RAG** - un sistema RAG que toma decisiones inteligentes sobre cu√°ndo recuperar documentos, c√≥mo evaluar su relevancia, y cu√°ndo reformular preguntas para mejorar los resultados.

---

## üîß Adaptaciones Realizadas

### 1. Imports actualizados (LangChain 1.0+)
```python
# ‚ùå ANTES (deprecado)
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain.chat_models import init_chat_model

# ‚úÖ DESPU√âS (LangChain 1.0+)
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_groq import ChatGroq
```

### 2. LLM (OpenAI ‚Üí Groq)
```python
# ‚ùå ANTES
llm_model = "openai:"+os.getenv("OPENAI_MODEL")
response_model = init_chat_model(llm_model, temperature=0)

# ‚úÖ DESPU√âS
llm_model = os.getenv("OPENAI_MODEL")  # llama-3.1-8b-instant
response_model = ChatGroq(model=llm_model, temperature=0)
```

### 3. Embeddings (OpenAI ‚Üí HuggingFace)
```python
# ‚ùå ANTES
vectorstore = InMemoryVectorStore.from_documents(
    documents=doc_splits, embedding=OpenAIEmbeddings()
)

# ‚úÖ DESPU√âS
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
vectorstore = InMemoryVectorStore.from_documents(
    documents=doc_splits, embedding=embeddings
)
```

### 4. Dependencias instaladas
```bash
# Ya instaladas en .venv:
pip install pypdf langgraph langchain-huggingface langchain-groq
```

---

## üìö Conceptos Clave

### 1. **Agentic RAG vs RAG tradicional**

| Aspecto | RAG Tradicional | Agentic RAG |
|---------|----------------|-------------|
| Flujo | Lineal: Query ‚Üí Retrieve ‚Üí Generate | Din√°mico con decisiones |
| Decisiones | Ninguna | M√∫ltiples nodos de decisi√≥n |
| Calidad | Dependiente de la query inicial | Auto-mejora con re-evaluaci√≥n |
| Flexibilidad | Limitada | Alta (puede saltar retrieval) |

### 2. **Componentes del Flujo Agentic RAG**

#### A. **Query Generation Node**
Decide si la pregunta necesita b√∫squeda en documentos o puede responderse directamente:
```python
def generate_query_or_respond(state: MessagesState):
    response = response_model.bind_tools([retriever_tool]).invoke(state["messages"])
    return {"messages": [response]}
```
- Si la pregunta es simple ("hello!"), responde directamente
- Si necesita contexto, invoca la herramienta de retrieval

#### B. **Document Grading Node**
Eval√∫a si los documentos recuperados son relevantes:
```python
class GradeDocuments(BaseModel):
    binary_score: str = Field(description="'yes' or 'no'")

def grade_documents(state: MessagesState):
    # Usa LLM para determinar relevancia
    score = grader_model.with_structured_output(GradeDocuments).invoke(...)
    if score == "yes":
        return "generate_answer"
    else:
        return "rewrite_question"
```

#### C. **Question Rewriting Node**
Si los documentos no son relevantes, reformula la pregunta:
```python
def rewrite_question(state: MessagesState):
    question = messages[0].content
    prompt = REWRITE_PROMPT.format(question=question)
    response = response_model.invoke([{"role": "user", "content": prompt}])
    return {"messages": [{"role": "user", "content": response.content}]}
```

#### D. **Answer Generation Node**
Genera la respuesta final usando el contexto:
```python
def generate_answer(state: MessagesState):
    question = state["messages"][0].content
    context = state["messages"][-1].content
    prompt = GENERATE_PROMPT.format(question=question, context=context)
    response = response_model.invoke([{"role": "user", "content": prompt}])
    return {"messages": [response]}
```

### 3. **LangGraph Workflow**

```mermaid
graph TD
    START --> generate_query_or_respond
    generate_query_or_respond -->|needs retrieval| retrieve
    generate_query_or_respond -->|direct answer| END
    retrieve --> grade_documents
    grade_documents -->|relevant| generate_answer
    grade_documents -->|not relevant| rewrite_question
    rewrite_question --> generate_query_or_respond
    generate_answer --> END
```

**Componentes clave:**
- **Nodes**: Funciones que procesan el estado
- **Edges**: Conexiones entre nodos (condicionales o fijas)
- **State**: `MessagesState` compartido entre todos los nodos
- **Conditional Edges**: Toman decisiones basadas en output del nodo

---

## üìù Estructura del Notebook

### Celdas 1-4: Setup e Imports
- Configuraci√≥n de entorno y dependencias

### Celdas 5-13: Ingesta de Documentos
- Carga del PDF sobre cambio clim√°tico
- Split en chunks de 1000 caracteres
- Creaci√≥n de vectorstore con embeddings locales

### Celdas 14-18: Retriever Tool
- Configuraci√≥n de herramienta de b√∫squeda
- Test b√°sico de retrieval

### Celdas 19-21: Node 1 - Query Generation
- Decisi√≥n: ¬øBuscar en docs o responder directo?
- Tests con diferentes tipos de queries

### Celdas 22-27: Node 2 - Document Grading
- Evaluaci√≥n de relevancia con LLM
- Tests con contextos relevantes e irrelevantes

### Celdas 28-31: Node 3 - Question Rewriting
- Reformulaci√≥n de preguntas poco claras
- Tests de mejora sem√°ntica

### Celdas 32-34: Node 4 - Answer Generation
- Generaci√≥n de respuesta con contexto
- Formato conciso (m√°x 3 oraciones)

### Celdas 35-43: Graph Assembly & Execution
- Construcci√≥n del workflow completo
- Visualizaci√≥n del grafo con Mermaid
- Ejecuci√≥n con streaming de resultados

### Celdas 44-45: Follow-up
- Sugerencias de mejoras (hallucination check, web search)
- Link a Adaptive RAG tutorial

---

## üéì Aprendizajes Clave

### 1. Ventajas de Agentic RAG

‚úÖ **Auto-correcci√≥n**: Si los docs no son relevantes, reescribe la query
‚úÖ **Eficiencia**: Puede responder sin retrieval si no es necesario
‚úÖ **Mejor calidad**: Evaluaci√≥n de relevancia antes de generar respuesta
‚úÖ **Transparencia**: Puedes ver cada paso del proceso (streaming)

### 2. Cu√°ndo usar Agentic RAG

- ‚úÖ Queries ambiguas o mal formuladas
- ‚úÖ Corpus documental grande y diverso
- ‚úÖ Necesitas trazabilidad del proceso de decisi√≥n
- ‚úÖ Calidad > Velocidad
- ‚ùå Latencia cr√≠tica (m√°s lento que RAG tradicional)
- ‚ùå Queries muy espec√≠ficas y bien formuladas

### 3. Diferencias con react-web-search.ipynb

| Aspecto | react-web-search | agentic-rag |
|---------|-----------------|-------------|
| Fuente de datos | Web (Tavily API) | Documentos locales |
| Herramientas | Web search | Retriever vectorstore |
| Uso | Info actualizada | Corpus propio |
| Complejidad | Media | Alta |

### 4. InMemoryVectorStore vs Chroma

- **InMemoryVectorStore**: Simple, r√°pido, no persiste
- **Chroma**: Persistente, m√°s features, ideal para producci√≥n
- Para aprendizaje: InMemoryVectorStore es suficiente

---

## üîç Ejemplo de Flujo Completo

**Input:** "what are the main reasons for climate change?"

**Paso 1 - Generate Query:**
```
Decisi√≥n: Necesita retrieval ‚Üí Invoca retriever_tool
```

**Paso 2 - Retrieve:**
```
Retorna 4 chunks relevantes sobre causas del cambio clim√°tico
```

**Paso 3 - Grade Documents:**
```
Evaluaci√≥n: Documentos contienen keywords relevantes
Score: "yes" ‚Üí Procede a generate_answer
```

**Paso 4 - Generate Answer:**
```
"The main reasons for climate change include the increase in
greenhouse gases, such as carbon dioxide and methane, primarily
due to human activities like burning fossil fuels and deforestation."
```

---

## ‚úÖ Checklist

- [x] Imports actualizados a LangChain 1.0+
- [x] LLM migrado a Groq (llama-3.1-8b-instant)
- [x] Embeddings migrados a HuggingFace (all-MiniLM-L6-v2)
- [x] Dependencias instaladas (pypdf, langgraph)
- [x] PDF de ejemplo disponible (Understanding_Climate_Change.pdf)
- [x] Tests de cada nodo funcionando
- [x] Graph assembly correcto
- [x] Documentaci√≥n creada

---

## üéØ Pr√≥ximos Pasos

1. **Experimentar con el notebook:**
   - Probar diferentes queries
   - Ver el streaming en acci√≥n
   - Modificar los prompts de grading/rewriting

2. **Mejoras sugeridas:**
   - Agregar hallucination check (validar si la respuesta est√° basada en el contexto)
   - Integrar web search como fuente adicional (Adaptive RAG)
   - Agregar logging para debugging

3. **Siguiente notebook:**
   - `sql-agent.ipynb` - Agentes que interact√∫an con bases de datos SQL

---

## üìñ Referencias

- **Adaptive RAG Tutorial:** https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_adaptive_rag/
- **LangGraph Docs:** https://langchain-ai.github.io/langgraph/
- **Agentic RAG Paper:** CRAG (Corrective RAG)

---

**Progreso:** 5/8 notebooks (62.5%)
**Prerequisitos completados:** ‚úÖ raglangchain.ipynb, ‚úÖ react-web-search.ipynb
