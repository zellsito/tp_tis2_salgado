# Aprendizaje: semanticsearchnotebook.ipynb

## üìã √çndice de Celdas

| # | ID | Tipo | Descripci√≥n | ¬øEjecutar? |
|---|-----|------|-------------|------------|
| 0 | 169f05af | Markdown | T√≠tulo: "Semantic Search with ChromaDB" | No ejecutable |
| 1 | 482c51f4 | Code | Instalaci√≥n de paquetes (comentada, ya instalado) | ‚úÖ Ejecutar |
| 2 | b51057d3 | Markdown | "Import Required Libraries" | No ejecutable |
| 3 | 3a43fb47 | Code | Imports (chromadb, pandas, SentenceTransformer) | ‚úÖ Ejecutar |
| 4 | cd5da066 | Markdown | "Setup Environment and API Keys" | No ejecutable |
| 5 | a3fbd451 | Code | Setup modelo local (all-MiniLM-L6-v2) | ‚úÖ Ejecutar |
| 6 | 2ffba9e1 | Markdown | "Define File Paths" | No ejecutable |
| 7 | 4ced7289 | Code | Definir rutas (dataset.json, chroma_db/) | ‚úÖ Ejecutar |
| 8 | 1df4275d | Markdown | "Load and Explore the Dataset" | No ejecutable |
| 9 | c2c5cc4b | Code | Cargar dataset.json en DataFrame | ‚úÖ Ejecutar |
| 10 | 48fed881 | Markdown | "Preview the Data" | No ejecutable |
| 11 | 50ce16b3 | Code | Mostrar primeras 3 pel√≠culas | ‚úÖ Ejecutar |
| 12 | 321de5cf | Markdown | "Initialize ChromaDB" | No ejecutable |
| 13 | cd722937 | Code | Inicializar ChromaDB con SentenceTransformer | ‚úÖ Ejecutar |
| 14 | 9dupv6wbi08 | Markdown | "Force Collection Rebuild (Optional)" | No ejecutable |
| 15 | ec4b4kl00d4 | Code | Eliminar colecci√≥n existente (forzar recreaci√≥n) | ‚úÖ Ejecutar |
| 16 | 088d30c6 | Markdown | "Create or Load Collection" | No ejecutable |
| 17 | d3743ae9 | Code | Crear colecci√≥n y generar embeddings | ‚úÖ Ejecutar |
| 18 | 38de1556 | Markdown | "Define Search Function" | No ejecutable |
| 19 | 29e70d95 | Code | Definir funciones de b√∫squeda | ‚úÖ Ejecutar |
| 20 | d6b18c8c | Markdown | "Test the Semantic Search" | No ejecutable |
| 21 | a7578575 | Code | Probar b√∫squedas sem√°nticas | ‚úÖ Ejecutar |
| 22 | 40409578 | Markdown | "Interactive Search" | No ejecutable |
| 23 | e3d17e7c | Code | B√∫squeda interactiva personalizable | ‚úÖ Ejecutar |
| 24 | 3726d9b2 | Markdown | "Advanced Search Analysis" | No ejecutable |
| 25 | da226254 | Code | Funci√≥n an√°lisis detallado con scores | ‚úÖ Ejecutar |
| 26 | 713283a3 | Code | Ejecutar an√°lisis detallado | ‚úÖ Ejecutar |
| 27 | 0aafeb1f | Markdown | "Collection Statistics" | No ejecutable |
| 28 | e9be5ad3 | Code | Estad√≠sticas de la colecci√≥n | ‚úÖ Ejecutar |
| 29 | 7e06cce9 | Markdown | "Cleanup and Summary" | No ejecutable |
| 30 | 5678ae8b | Code | Resumen final del sistema | ‚úÖ Ejecutar |

**Total:** 31 celdas (16 ejecutables, 15 markdown)

---

## üîß Errores Encontrados y Corregidos

### Error 1: Embeddings de OpenAI (dimensi√≥n incompatible)
**Problema:** Dataset conten√≠a embeddings pre-calculados de OpenAI (dimensi√≥n 1536), pero el notebook usa modelo local (dimensi√≥n 384)

```python
# ‚ùå Error al ejecutar b√∫squeda
InvalidArgumentError: Collection expecting embedding with dimension of 1536, got 384
```

**Causa:**
1. `dataset.json` original ten√≠a embeddings de OpenAI pre-calculados
2. ChromaDB cre√≥ colecci√≥n con dimensi√≥n 1536
3. Nuevo modelo local `all-MiniLM-L6-v2` genera dimensi√≥n 384
4. Dimensiones incompatibles

**Soluci√≥n aplicada:**
1. **Limpiar dataset.json** (eliminar embeddings pre-calculados)
2. **Crear backup:** `dataset_original_with_openai_embeddings.json` (210KB)
3. **Nuevo dataset.json:** 8.6KB (sin embeddings)
4. **Eliminar colecci√≥n ChromaDB** antigua
5. **Regenerar embeddings** con modelo local

---

### Error 2: Colecci√≥n vac√≠a (b√∫squeda sin resultados)
**Problema:** B√∫squeda sem√°ntica no retornaba resultados

```python
# ‚ùå B√∫squeda no encontraba nada
üîç Search Results for: 'superhero adventure'
No results found.
```

**Causa:**
1. Colecci√≥n existente estaba vac√≠a (0 documentos)
2. C√≥digo entraba en bloque `try` (cargaba colecci√≥n vac√≠a)
3. NUNCA ejecutaba bloque `except` (que agrega documentos)

**Soluci√≥n:**
Agregar celda de forzar recreaci√≥n (celda 15) que elimina colecci√≥n existente antes de crear nueva.

---

### Error 3: Uso de embeddings pre-calculados
**Problema:** C√≥digo intentaba usar `df.embedding.tolist()` que no existe en dataset limpio

```python
# ‚ùå C√≥digo antiguo (celda d3743ae9)
movies_collection.add(
    embeddings=df.embedding.tolist(),  # ‚ùå Campo no existe
    metadatas=metadatas
)

# ‚úÖ C√≥digo actualizado
movies_collection.add(
    documents=documents,  # ChromaDB genera embeddings autom√°ticamente
    metadatas=metadatas
)
```

---

## üìö Conceptos Clave

### 1. **Embeddings (Vectores de texto)**
Representaci√≥n num√©rica de texto en espacio vectorial de 384 dimensiones.
- Textos similares ‚Üí vectores cercanos
- Permite b√∫squeda sem√°ntica (no solo keywords)
- Modelo usado: `all-MiniLM-L6-v2`

### 2. **ChromaDB (Base de datos vectorial)**
Base de datos especializada en almacenar y buscar embeddings.
- Almacenamiento persistente en disco
- Genera embeddings autom√°ticamente
- B√∫squeda por similitud vectorial

### 3. **B√∫squeda Sem√°ntica (Similarity Search)**
Buscar por significado, no por palabras exactas.
- Distancia baja = m√°s similar
- Usa distancia euclidiana
- Retorna top-k resultados m√°s similares

### 4. **SentenceTransformers**
Modelo open-source de HuggingFace para generar embeddings.
- ‚úÖ Gratuito (no requiere API key)
- ‚úÖ Local (no env√≠a datos externos)
- ‚úÖ R√°pido (~90MB modelo)

---

## üéØ Resumen Ejecutivo

### Tecnolog√≠as Principales

| Tecnolog√≠a | Prop√≥sito |
|------------|-----------|
| **ChromaDB** | Base de datos vectorial |
| **SentenceTransformers** | Generar embeddings |
| **all-MiniLM-L6-v2** | Modelo de embeddings (384 dim) |
| **Pandas** | Manipulaci√≥n de datos |

### M√©tricas del Sistema

| M√©trica | Valor |
|---------|-------|
| Total pel√≠culas | 10 |
| Dimensi√≥n embeddings | 384 |
| Tama√±o dataset | 8.6KB |
| Tiempo generaci√≥n embeddings | ~5-10 segundos |

### Flujo de Datos

```
1. Cargar dataset.json
   ‚Üì
2. Convertir a DataFrame
   ‚Üì
3. Preparar textos (title + overview)
   ‚Üì
4. ChromaDB genera embeddings
   ‚Üì
5. Almacenar en colecci√≥n
   ‚Üì
6. B√∫squeda: query ‚Üí embedding ‚Üí similarity
   ‚Üì
7. Retornar resultados ordenados
```

---

## ‚úÖ Checklist de Ejecuci√≥n

- [x] Limpiar `dataset.json` (eliminar embeddings OpenAI)
- [x] Crear backup `dataset_original_with_openai_embeddings.json`
- [x] Ejecutar celdas 1-5 (setup e imports)
- [x] Ejecutar celda 7 (definir rutas)
- [x] Ejecutar celda 9 (cargar dataset)
- [x] Ejecutar celda 11 (preview datos)
- [x] Ejecutar celda 13 (inicializar ChromaDB)
- [x] Ejecutar celda 15 (eliminar colecci√≥n antigua) ‚ö†Ô∏è CR√çTICO
- [x] Ejecutar celda 17 (crear colecci√≥n y generar embeddings)
- [x] Ejecutar celda 19 (definir funciones)
- [x] Ejecutar celda 21 (probar b√∫squedas)
- [x] Ejecutar celda 23 (b√∫squeda interactiva)
- [x] Ejecutar celda 25-26 (an√°lisis detallado)
- [x] Ejecutar celda 28 (estad√≠sticas)
- [x] Ejecutar celda 30 (resumen)

---

## üéì Aprendizajes Clave

### 1. Embeddings vs Texto
Los embeddings son la representaci√≥n matem√°tica del significado del texto.

### 2. ChromaDB: Automatizaci√≥n
ChromaDB genera embeddings autom√°ticamente si proporcionas `documents=`.

### 3. Persistencia
`PersistentClient` guarda en disco, no necesitas regenerar cada vez.

### 4. B√∫squeda Sem√°ntica ‚â† Keywords
Entiende el significado, no solo coincidencias literales.

### 5. Modelo Local vs API
Usar `all-MiniLM-L6-v2` es gratis y privado (vs OpenAI de pago).

### 6. Dimensionalidad importa
No puedes mezclar embeddings de diferentes dimensiones.

---

## üìù Notas Finales

### Archivos Generados

```
notebooks/
‚îú‚îÄ‚îÄ dataset.json                                    # 8.6KB (limpio)
‚îú‚îÄ‚îÄ dataset_original_with_openai_embeddings.json    # 210KB (backup)
‚îú‚îÄ‚îÄ chroma_db/                                      # Base de datos vectorial
‚îî‚îÄ‚îÄ semanticsearchnotebook.ipynb                    # Notebook ejecutado
```

### Comparaci√≥n con chatmodel.ipynb

| Aspecto | chatmodel.ipynb | semanticsearchnotebook.ipynb |
|---------|-----------------|------------------------------|
| **Enfoque** | LLMs y prompting | B√∫squeda vectorial |
| **Tecnolog√≠a** | LangChain + Groq | ChromaDB + SentenceTransformers |
| **Output** | Texto generado | Documentos similares |
| **Uso** | Chatbots, QA | B√∫squeda, recomendaci√≥n |

**Sinergia:** Estos notebooks se complementan para construir RAG:
1. semanticsearchnotebook: Buscar documentos relevantes
2. chatmodel: Generar respuestas basadas en esos documentos

---

**Pr√≥ximo notebook recomendado:** `raglangchain.ipynb` (combina b√∫squeda sem√°ntica + LLM)
