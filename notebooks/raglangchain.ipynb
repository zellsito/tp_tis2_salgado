{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5731d9df",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ded929",
   "metadata": {},
   "source": [
    "Importing necessary libraries and installing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61671a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "import shutil \n",
    "from IPython.display import display, Markdown\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0359a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ IMPORTS ACTUALIZADOS para LangChain 1.0+\n",
    "\n",
    "# Document loaders\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader, PyPDFLoader\n",
    "\n",
    "# Text splitters\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Embeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Core components\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.vectorstores import InMemoryVectorStore  \n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Vector stores\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# LLM\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Hub for prompts (using langsmith)\n",
    "from langsmith import Client as LangSmithClient\n",
    "hub_client = LangSmithClient()\n",
    "\n",
    "# Cross encoders\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2635fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pypdf langchain-huggingface sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e892c050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8o9x9mda5pj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Configurar modelo de embeddings local (HuggingFace)\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "\n",
    "print(f\"‚úÖ Embedding model: {EMBEDDING_MODEL} (local, free)\")\n",
    "print(f\"üì¶ Will download model on first use (~90MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db4e0a7",
   "metadata": {},
   "source": [
    "## Leveraging Semantic Search (with movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cab636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the same dataset as in the other notebook\n",
    "# input_datapath = \"../semantic-search/dataset.json\"  # ‚ùå Antiguo: path incorrecto\n",
    "input_datapath = \"dataset.json\"  # ‚úÖ Usar dataset en mismo directorio\n",
    "\n",
    "with open(input_datapath, 'r') as f:\n",
    "    movie_data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(movie_data)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ce6a0d",
   "metadata": {},
   "source": [
    "We will create one document per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3834fa36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 documents\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "documents = []\n",
    "for index, row in df.iterrows():\n",
    "    genres = ast.literal_eval(row['genres'])\n",
    "    md_dict = {\n",
    "        \"language\": row['original_language'], \n",
    "        \"genre\": genres[0], \n",
    "        \"release_date\": row['release_date'],\n",
    "        \"source\": index\n",
    "    }\n",
    "    doc = Document(id=index, page_content=row['title']+\" - \"+row['overview'], metadata=md_dict)\n",
    "    documents.append(doc)\n",
    "print(len(documents), \"documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86929239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='0', metadata={'language': 'English', 'genre': 'Horror', 'release_date': '2023-04-05', 'source': 0}, page_content=\"The Pope's Exorcist - Father Gabriele Amorth, Chief Exorcist of the Vatican, investigates a young boy's terrifying possession and ends up uncovering a centuries-old conspiracy the Vatican has desperately tried to keep hidden.\"),\n",
       " Document(id='1', metadata={'language': 'English', 'genre': 'Action', 'release_date': '2023-02-15', 'source': 1}, page_content=\"Ant-Man and the Wasp: Quantumania - Super-Hero partners Scott Lang and Hope van Dyne, along with with Hope's parents Janet van Dyne and Hank Pym, and Scott's daughter Cassie Lang, find themselves exploring the Quantum Realm, interacting with strange new creatures and embarking on an adventure that will push them beyond the limits of what they thought possible.\"),\n",
       " Document(id='2', metadata={'language': 'English', 'genre': 'Action', 'release_date': '2023-04-18', 'source': 2}, page_content='Ghosted - Salt-of-the-earth Cole falls head over heels for enigmatic Sadie ‚Äî but then makes the shocking discovery that she‚Äôs a secret agent. Before they can decide on a second date, Cole and Sadie are swept away on an international adventure to save the world.'),\n",
       " Document(id='3', metadata={'language': 'English', 'genre': 'Action', 'release_date': '2023-03-15', 'source': 3}, page_content='Shazam! Fury of the Gods - Billy Batson and his foster siblings, who transform into superheroes by saying \"Shazam!\", are forced to get back into action and fight the Daughters of Atlas, who they must stop from using a weapon that could destroy the world.'),\n",
       " Document(id='4', metadata={'language': 'English', 'genre': 'Science Fiction', 'release_date': '2022-12-14', 'source': 4}, page_content='Avatar: The Way of Water - Set more than a decade after the events of the first film, learn the story of the Sully family (Jake, Neytiri, and their kids), the trouble that follows them, the lengths they go to keep each other safe, the battles they fight to stay alive, and the tragedies they endure.'),\n",
       " Document(id='5', metadata={'language': 'English', 'genre': 'Science Fiction', 'release_date': '2023-05-03', 'source': 5}, page_content='Guardians of the Galaxy Volume 3 - Peter Quill, still reeling from the loss of Gamora, must rally his team around him to defend the universe along with protecting one of their own. A mission that, if not completed successfully, could quite possibly lead to the end of the Guardians as we know them.'),\n",
       " Document(id='6', metadata={'language': 'English', 'genre': 'Horror', 'release_date': '2023-03-08', 'source': 6}, page_content='Scream VI - Following the latest Ghostface killings, the four survivors leave Woodsboro behind and start a fresh chapter.'),\n",
       " Document(id='7', metadata={'language': 'English', 'genre': 'Drama', 'release_date': '2023-03-01', 'source': 7}, page_content='Creed III - After dominating the boxing world, Adonis Creed has been thriving in both his career and family life. When a childhood friend and former boxing prodigy, Damian Anderson, resurfaces after serving a long sentence in prison, he is eager to prove that he deserves his shot in the ring. The face-off between former friends is more than just a fight. To settle the score, Adonis must put his future on the line to battle Damian ‚Äî a fighter who has nothing to lose.'),\n",
       " Document(id='8', metadata={'language': 'English', 'genre': 'Adventure', 'release_date': '2023-03-23', 'source': 8}, page_content='Dungeons & Dragons: Honor Among Thieves - A charming thief and a band of unlikely adventurers undertake an epic heist to retrieve a lost relic, but things go dangerously awry when they run afoul of the wrong people.'),\n",
       " Document(id='9', metadata={'language': 'English', 'genre': 'Family', 'release_date': '2023-04-20', 'source': 9}, page_content='Peter Pan & Wendy - Wendy Darling, a young girl afraid to leave her childhood home behind, meets Peter Pan, a boy who refuses to grow up. Alongside her brothers and a tiny fairy, Tinker Bell, she travels with Peter to the magical world of Neverland. There, she encounters an evil pirate captain, Captain Hook, and embarks on a thrilling adventure that will change her life forever.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b581fc",
   "metadata": {},
   "source": [
    "We store all the movies into an in-memory vector store for simplicity (it could be any other kind of vector store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd1aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore = InMemoryVectorStore(OpenAIEmbeddings())  # ‚ùå Antiguo\n",
    "vectorstore = InMemoryVectorStore(embeddings)  # ‚úÖ Usar embeddings locales\n",
    "_ = vectorstore.add_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75db1347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Document(id='0', metadata={'language': 'English', 'genre': 'Horror', 'release_date': '2023-04-05', 'source': 0}, page_content=\"The Pope's Exorcist - Father Gabriele Amorth, Chief Exorcist of the Vatican, investigates a young boy's terrifying possession and ends up uncovering a centuries-old conspiracy the Vatican has desperately tried to keep hidden.\"), 0.7919395004819728)\n",
      "(Document(id='3', metadata={'language': 'English', 'genre': 'Action', 'release_date': '2023-03-15', 'source': 3}, page_content='Shazam! Fury of the Gods - Billy Batson and his foster siblings, who transform into superheroes by saying \"Shazam!\", are forced to get back into action and fight the Daughters of Atlas, who they must stop from using a weapon that could destroy the world.'), 0.7548893852785512)\n"
     ]
    }
   ],
   "source": [
    "def _filter_function(doc: Document) -> bool:\n",
    "    return doc.metadata.get(\"genre\") == 'Horror'\n",
    "\n",
    "# Alternative ways of performing a semantic search\n",
    "\n",
    "query = \"Something about religion\"\n",
    "#¬†results = vectorstore.similarity_search(query, k=2)\n",
    "results = vectorstore.similarity_search_with_score(query, k=2)\n",
    "#¬†results = vectorstore.similarity_search_with_score(query, k=2, filter=_filter_function)\n",
    "\n",
    "for r in results:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34758260",
   "metadata": {},
   "source": [
    "In Langchain, we often use a *retriever* on top of the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5eb538a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='0', metadata={'language': 'English', 'genre': 'Horror', 'release_date': '2023-04-05', 'source': 0}, page_content=\"The Pope's Exorcist - Father Gabriele Amorth, Chief Exorcist of the Vatican, investigates a young boy's terrifying possession and ends up uncovering a centuries-old conspiracy the Vatican has desperately tried to keep hidden.\"),\n",
       " Document(id='3', metadata={'language': 'English', 'genre': 'Action', 'release_date': '2023-03-15', 'source': 3}, page_content='Shazam! Fury of the Gods - Billy Batson and his foster siblings, who transform into superheroes by saying \"Shazam!\", are forced to get back into action and fight the Daughters of Atlas, who they must stop from using a weapon that could destroy the world.'),\n",
       " Document(id='8', metadata={'language': 'English', 'genre': 'Adventure', 'release_date': '2023-03-23', 'source': 8}, page_content='Dungeons & Dragons: Honor Among Thieves - A charming thief and a band of unlikely adventurers undertake an epic heist to retrieve a lost relic, but things go dangerously awry when they run afoul of the wrong people.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\n",
    "        'k': 3\n",
    "    }\n",
    ")\n",
    "\n",
    "retriever.invoke(input=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a02b720",
   "metadata": {},
   "source": [
    "Let's create an LLM for the RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964b9696",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = os.environ[\"OPENAI_MODEL\"]  # Usa llama-3.1-8b-instant de Groq\n",
    "print(f\"ü§ñ LLM model: {llm_model}\")\n",
    "\n",
    "# llm = ChatOpenAI(model=llm_model, temperature=0.1)  # ‚ùå Antiguo: OpenAI\n",
    "llm = ChatGroq(model=llm_model, temperature=0.1)  # ‚úÖ Nuevo: Groq (gratis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2afce3e",
   "metadata": {},
   "source": [
    "The typical RAG prompt considers the *context* and the *question*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f41466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for a public prompt (https://smith.langchain.com/hub/rlm/rag-prompt)\n",
    "# ‚ùå Antiguo: rag_prompt = hub.pull(\"rlm/rag-prompt\", include_model=True)\n",
    "\n",
    "# ‚úÖ Nuevo: Usar langsmith Client con pull_prompt()\n",
    "rag_prompt = hub_client.pull_prompt(\"rlm/rag-prompt\")\n",
    "\n",
    "# Mostrar el template del prompt\n",
    "rag_prompt.messages[0].prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d043a5",
   "metadata": {},
   "source": [
    "A basic chain that connects to the retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0fa7192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You might consider watching \"The Pope's Exorcist,\" which involves themes of religion as it follows Father Gabriele Amorth investigating a young boy's possession and uncovering a Vatican conspiracy."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The prompt is predefined, but other prompts could be used\n",
    "rag_chain = (\n",
    "    {\"context\": retriever,  \"question\": RunnablePassthrough()} \n",
    "    | rag_prompt \n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "query = \"I want to get a movie about religion\"\n",
    "result = rag_chain.invoke(query)\n",
    "#¬†pprint.pprint(result)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bfc396",
   "metadata": {},
   "source": [
    "## Ingestion (chunks) and RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfb6df35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 loaded\n"
     ]
    }
   ],
   "source": [
    "# We consider a large PDF file\n",
    "pdf_path = \"./data/Understanding_Climate_Change.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "pdf_documents = loader.load() # Each document corresponds actually to a page\n",
    "print(len(pdf_documents), \"loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dbf9e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 chunks\n"
     ]
    }
   ],
   "source": [
    "def replace_t_with_space(list_of_documents):\n",
    "    for doc in list_of_documents:\n",
    "        doc.page_content = doc.page_content.replace('\\t', ' ')  # Replace tabs with spaces\n",
    "    return list_of_documents\n",
    "\n",
    "\n",
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "texts = text_splitter.split_documents(pdf_documents)\n",
    "cleaned_texts = replace_t_with_space(texts)\n",
    "print(len(cleaned_texts), \"chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1779f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a vector store for the chunks\n",
    "# vectorstore = Chroma.from_documents(cleaned_texts, OpenAIEmbeddings())  # ‚ùå Antiguo\n",
    "vectorstore = Chroma.from_documents(cleaned_texts, embeddings)  # ‚úÖ Usar embeddings locales\n",
    "my_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32fbc53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "change the amount of solar energy our planet receives. During the Holocene epoch, which \n",
      "began at the end of the last ice age, human societies flourished, but the industrial era has seen \n",
      "unprecedented changes. \n",
      "Modern Observations \n",
      "Modern scientific observations indicate a rapid increase in global temperatures, sea levels, \n",
      "and extreme weather events. The Intergovernmental Panel on Climate Change (IPCC) has \n",
      "documented these changes extensively. Ice core samples, tree rings, and ocean sediments \n",
      "provide a historical record that scientists use to understand past climate conditions and \n",
      "predict future trends. The evidence overwhelmingly shows that recent changes are primarily \n",
      "driven by human activities, particularly the emission of greenhouse gases. \n",
      "Chapter 2: Causes of Climate Change \n",
      "Greenhouse Gases \n",
      "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
      "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Understanding Climate Change \n",
      "Chapter 1: Introduction to Climate Change \n",
      "Climate change refers to significant, long-term changes in the global climate. The term \n",
      "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
      "precipitation, and wind patterns, over an extended period. Over the past century, human \n",
      "activities, particularly the burning of fossil fuels and deforestation, have significantly \n",
      "contributed to climate change. \n",
      "Historical Context \n",
      "The Earth's climate has changed throughout history. Over the past 650,000 years, there have \n",
      "been seven cycles of glacial advance and retreat, with the abrupt end of the last ice age about \n",
      "11,700 years ago marking the beginning of the modern climate era and human civilization. \n",
      "Most of these climate changes are attributed to very small variations in Earth's orbit that \n",
      "change the amount of solar energy our planet receives. During the Holocene epoch, which\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Climate change is linked to an increase in the frequency and severity of extreme weather \n",
      "events, such as hurricanes, heatwaves, droughts, and heavy rainfall. These events can have \n",
      "devastating impacts on communities, economies, and ecosystems. \n",
      "Hurricanes and Typhoons \n",
      "Warmer ocean temperatures can intensify hurricanes and typhoons, leading to more \n",
      "destructive storms. Coastal regions are at heightened risk of storm surge and flooding. Early \n",
      "warning systems and resilient infrastructure are critical for mitigating these risks. \n",
      "Droughts \n",
      "Increased temperatures and changing precipitation patterns are contributing to more frequent \n",
      "and severe droughts. This affects agriculture, water supply, and ecosystems, particularly in \n",
      "arid and semi-arid regions. Droughts can lead to food and water shortages and exacerbate \n",
      "conflicts. \n",
      "Flooding \n",
      "Heavy rainfall events are becoming more common, leading to increased flooding. Urban\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous \n",
      "oxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is essential \n",
      "for life on Earth, as it keeps the planet warm enough to support life. However, human \n",
      "activities have intensified this natural process, leading to a warmer climate. \n",
      "Fossil Fuels \n",
      "Burning fossil fuels for energy releases large amounts of CO2. This includes coal, oil, and \n",
      "natural gas used for electricity, heating, and transportation. The industrial revolution marked \n",
      "the beginning of a significant increase in fossil fuel consumption, which continues to rise \n",
      "today. \n",
      "Coal\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "agricultural sector's carbon footprint. \n",
      "Chapter 3: Effects of Climate Change \n",
      "The effects of climate change are already being felt around the world and are projected to \n",
      "intensify in the coming decades. These effects include: \n",
      "Rising Temperatures \n",
      "Global temperatures have risen by about 1.2 degrees Celsius (2.2 degrees Fahrenheit) since \n",
      "the late 19th century. This warming is not uniform, with some regions experiencing more \n",
      "significant increases than others. \n",
      "Heatwaves \n",
      "Heatwaves are becoming more frequent and severe, posing risks to human health, agriculture, \n",
      "and infrastructure. Cities are particularly vulnerable due to the \"urban heat island\" effect. \n",
      "Heatwaves can lead to heat-related illnesses and exacerbate existing health conditions. \n",
      "Changing Seasons \n",
      "Climate change is altering the timing and length of seasons, affecting ecosystems and human \n",
      "activities. For example, spring is arriving earlier, and winters are becoming shorter and\n"
     ]
    }
   ],
   "source": [
    "# Helper function for printing docs\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i + 1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "test_query = \"What is the main cause of climate change?\"\n",
    "context_docs =  my_retriever.invoke(test_query)\n",
    "pretty_print_docs(context_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41861acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I don't know."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Then. we apply the RAG chain\n",
    "rag_chain = (\n",
    "    {\"context\": my_retriever,  \"question\": RunnablePassthrough()} \n",
    "    | rag_prompt \n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "test_query = \"What was the latest storm on Earth?\"\n",
    "result = rag_chain.invoke(test_query)\n",
    "#¬†pprint.pprint(result)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327030d0",
   "metadata": {},
   "source": [
    "## Re-Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72a8856",
   "metadata": {},
   "source": [
    "In this example, we use a cross-encoding strategy from HuggingFace, but other strategies can be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3652ba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ IMPLEMENTACI√ìN MANUAL DE RE-RANKING con HuggingFaceCrossEncoder\n",
    "# ContextualCompressionRetriever no est√° disponible en LangChain 1.0+\n",
    "# Implementamos re-ranking manual usando cross-encoder directamente\n",
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Cargar el modelo cross-encoder para re-ranking\n",
    "cross_encoder_model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "def rerank_documents(query: str, documents: list, top_n: int = 3):\n",
    "    \"\"\"\n",
    "    Re-rankea documentos usando un cross-encoder.\n",
    "    \n",
    "    Args:\n",
    "        query: La pregunta del usuario\n",
    "        documents: Lista de documentos recuperados\n",
    "        top_n: N√∫mero de documentos top a retornar\n",
    "    \n",
    "    Returns:\n",
    "        Lista de documentos re-rankeados (top_n mejores)\n",
    "    \"\"\"\n",
    "    # Crear pares (query, documento) para el cross-encoder\n",
    "    pairs = [[query, doc.page_content] for doc in documents]\n",
    "    \n",
    "    # Obtener scores de relevancia\n",
    "    scores = cross_encoder_model.predict(pairs)\n",
    "    \n",
    "    # Ordenar documentos por score (descendente)\n",
    "    scored_docs = list(zip(documents, scores))\n",
    "    scored_docs.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Retornar top_n documentos\n",
    "    reranked_docs = [doc for doc, score in scored_docs[:top_n]]\n",
    "    \n",
    "    # Imprimir scores para debugging\n",
    "    print(f\"Re-ranking results (top {top_n}):\")\n",
    "    for i, (doc, score) in enumerate(scored_docs[:top_n], 1):\n",
    "        preview = doc.page_content[:100].replace('\\n', ' ')\n",
    "        print(f\"  {i}. Score: {score:.4f} - {preview}...\")\n",
    "    \n",
    "    return reranked_docs\n",
    "\n",
    "print(\"‚úÖ Re-ranking function implemented with cross-encoder/ms-marco-MiniLM-L-6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7250b7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Probar re-ranking con documentos del retriever\n",
    "# Primero obtenemos m√°s documentos (k=10), luego re-rankeamos a top 3\n",
    "\n",
    "# Obtener documentos del retriever (sin re-ranking)\n",
    "initial_docs = my_retriever.invoke(test_query)\n",
    "print(f\"\\nInitial retrieval: {len(initial_docs)} documents\")\n",
    "\n",
    "# Aplicar re-ranking manual\n",
    "reranked_docs = rerank_documents(test_query, initial_docs, top_n=3)\n",
    "\n",
    "print(f\"\\n{'-'*100}\\nRe-ranked documents:\\n{'-'*100}\")\n",
    "pretty_print_docs(reranked_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1316d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ RAG Chain con re-ranking integrado\n",
    "# Creamos un retriever personalizado que incluye re-ranking\n",
    "\n",
    "class RerankedRetriever:\n",
    "    \"\"\"Retriever personalizado que aplica re-ranking autom√°ticamente\"\"\"\n",
    "    \n",
    "    def __init__(self, base_retriever, rerank_function, top_n=3):\n",
    "        self.base_retriever = base_retriever\n",
    "        self.rerank_function = rerank_function\n",
    "        self.top_n = top_n\n",
    "    \n",
    "    def invoke(self, query: str):\n",
    "        \"\"\"Obtiene documentos y los re-rankea\"\"\"\n",
    "        # Obtener documentos iniciales\n",
    "        docs = self.base_retriever.invoke(query)\n",
    "        # Aplicar re-ranking\n",
    "        reranked = self.rerank_function(query, docs, self.top_n)\n",
    "        return reranked\n",
    "\n",
    "# Crear retriever con re-ranking\n",
    "reranked_retriever = RerankedRetriever(\n",
    "    base_retriever=my_retriever,\n",
    "    rerank_function=rerank_documents,\n",
    "    top_n=3\n",
    ")\n",
    "\n",
    "# Crear RAG chain con re-ranking\n",
    "rag_chain_reranked = (\n",
    "    {\"context\": reranked_retriever.invoke,  \"question\": RunnablePassthrough()} \n",
    "    | rag_prompt \n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Probar el chain con re-ranking\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"RAG CHAIN WITH RE-RANKING\")\n",
    "print(\"=\"*100)\n",
    "result = rag_chain_reranked.invoke(test_query)\n",
    "print(\"\\nAnswer:\")\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison_rerank",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Comparaci√≥n: Sin re-ranking vs Con re-ranking\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"COMPARISON: WITHOUT vs WITH RE-RANKING\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Query de prueba\n",
    "comparison_query = \"What causes climate change?\"\n",
    "print(f\"\\nQuery: {comparison_query}\\n\")\n",
    "\n",
    "# 1. SIN RE-RANKING\n",
    "print(\"\\n[1] WITHOUT RE-RANKING (top 3 from vector search):\")\n",
    "print(\"-\"*100)\n",
    "docs_without = my_retriever.invoke(comparison_query)[:3]\n",
    "for i, doc in enumerate(docs_without, 1):\n",
    "    preview = doc.page_content[:120].replace('\\n', ' ')\n",
    "    print(f\"  {i}. {preview}...\")\n",
    "\n",
    "# 2. CON RE-RANKING\n",
    "print(f\"\\n[2] WITH RE-RANKING (cross-encoder scores):\")\n",
    "print(\"-\"*100)\n",
    "docs_with = rerank_documents(comparison_query, my_retriever.invoke(comparison_query), top_n=3)\n",
    "\n",
    "print(\"\\n‚úÖ Re-ranking mejora la relevancia de los documentos recuperados\")\n",
    "print(\"   (documentos con mayor score sem√°ntico seg√∫n el cross-encoder)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747ead03",
   "metadata": {},
   "source": [
    "## Bonus: Visualization of Chunks and Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b113ac",
   "metadata": {},
   "source": [
    "https://github.com/gabrielchua/RAGxplorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64463bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Ya instalado en .venv\n",
    "# %pip install ragexplorer nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b91c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragxplorer import RAGxplorer\n",
    "\n",
    "# ‚úÖ Usar modelo local all-MiniLM-L6-v2 (mismo que usamos en el resto del notebook)\n",
    "# Por defecto RAGxplorer usa \"all-MiniLM-L6-v2\" si no se especifica\n",
    "client = RAGxplorer(embedding_model=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Cargar el PDF y construir la base de datos vectorial\n",
    "client.load_pdf(\n",
    "    document_path=pdf_path, \n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d895962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Usar m√©todo \"naive\" (b√°sico) en lugar de \"HyDE\" \n",
    "# HyDE tiene un bug con embeddings locales en la versi√≥n actual de RAGxplorer\n",
    "client.visualize_query(\n",
    "    query=test_query, \n",
    "    retrieval_method=\"naive\",  # Opciones: \"naive\", \"HyDE\", \"multi_qns\"\n",
    "    top_k=6, \n",
    "    query_shape_size=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e60271",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia_desde_cero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
